[Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction)
* [Supervised Machine Learning: Regression and Classification](https://www.coursera.org/learn/machine-learning?specialization=machine-learning-introduction)
* [Advanced Learning Algorithms](https://www.coursera.org/learn/advanced-learning-algorithms?specialization=machine-learning-introduction)
* [Unsupervised Learning, Recommenders, Reinforcement Learning](https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning?specialization=machine-learning-introduction)


# Machine Learning: An Introduction

**Machine Learning (ML)** is the science of enabling computers to **learn without explicit programming**. You use it daily in many ways, like:

* **Web search** (ranking pages)
* **Image tagging** (recognizing friends)
* **Movie recommendations**
* **Voice assistants** (voice-to-text, Siri, Google Assistant)
* **Spam detection**

## Broader Applications

Beyond consumer apps, ML is transforming industries:

* **Climate change** (optimizing wind turbines)
* **Healthcare** (aiding diagnoses)
* **Manufacturing** (inspecting defects with computer vision)

# Machine Learning: Skills and Impact

This course teaches **state-of-the-art Machine Learning (ML) algorithms** used by top tech companies, along with **practical tips for effective implementation and performance**. You'll gain hands-on experience.

## Why ML is Essential Today

ML, a subfield of AI, addresses complex tasks difficult to program explicitly (e.g., web search, speech recognition, self-driving cars). Machines **learn to perform these tasks independently**.

ML is impacting nearly every industry, from healthcare and agriculture to manufacturing and e-commerce. Its applications are widespread, from **Google Brain and Baidu's AI initiatives** to **Landing.AI's factory automation**.

## The Future and Value of ML

While **Artificial General Intelligence (AGI)** is a distant goal, **learning algorithms are key** to advancing AI. ML is projected to add **$13 trillion USD to the global economy by 2030**, with vast untapped potential outside the software industry. This immense demand makes learning ML skills highly valuable now.

The next video will delve into the formal definition of ML and introduce its main types of problems and algorithms.

# What is Machine Learning?

Machine Learning (ML) is defined as the field of study that gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1950s). Samuel's checkers program, by playing tens of thousands of games against itself, learned to be a better player than Samuel, demonstrating that **more learning opportunities lead to better performance**.

## Main Types of Machine Learning

This course covers various ML algorithms, primarily focusing on:

1.  **Supervised Learning:** Most widely used in real-world applications and has seen rapid advancements. Covered in the first two courses of this specialization.
2.  **Unsupervised Learning:** Covered in the third course, along with recommender systems and reinforcement learning.

Supervised learning, unsupervised learning, and recommender systems are the most frequently used learning algorithms today.

## Practical Application

This specialization emphasizes **practical advice for applying ML algorithms effectively**. Beyond just understanding algorithms, you'll learn:

* How to apply ML tools effectively.
* Best practices for developing valuable ML systems, preventing common pitfalls.
* How skilled ML engineers design and build robust systems.

# Supervised Learning: Input to Output Mappings

**Supervised learning** constitutes nearly all economic value generated by machine learning today. It involves algorithms that learn **input (x) to output (y) mappings** by being given **examples with the correct answers (labels)**. The algorithm then predicts the output for new, unseen inputs.

## Examples of Supervised Learning

* **Spam Filter:** Input (email) -> Output (spam/not spam)
* **Speech Recognition:** Input (audio clip) -> Output (text transcript)
* **Machine Translation:** Input (English text) -> Output (Spanish text)
* **Online Advertising:** Input (ad/user info) -> Output (click/no click) - A highly lucrative application.
* **Self-driving Cars:** Input (image, sensor data) -> Output (position of other cars)
* **Visual Inspection (Manufacturing):** Input (product picture) -> Output (defect/no defect)

In all these cases, models are **trained with input-output (x, y) pairs** and then predict 'y' for new 'x' inputs.

## Housing Price Prediction: A Regression Example

Consider predicting house prices based on size. You provide the algorithm with a dataset of **house sizes (x)** and their **corresponding correct prices (y)**.

* When given a new house size (e.g., 750 sq ft), the algorithm, by fitting a line or curve to the data, can predict its price (e.g., $150,000 or $200,000).
* The course will teach how to systematically choose the best fit (line, curve, etc.).

This is **supervised learning** because the algorithm is given the "right answers" (prices) for training.

This specific type of supervised learning, where the output 'y' is a **continuous number** (like price), is called **regression**. The next video will cover **classification**, another major type of supervised learning, where the output is discrete.

# Supervised Learning: Classification

**Supervised learning algorithms predict input (X) to output (Y) mappings.** While **regression** predicts a **continuous number** (e.g., housing prices), **classification**, the second major type, predicts a **category** from a small, finite set of possibilities.

## Classification in Action: Breast Cancer Detection

In breast cancer detection, an ML system takes patient medical records (inputs) to classify a tumor as either **malignant (cancerous, denoted as 1)** or **benign (non-cancerous, denoted as 0)**.

* **Key Difference from Regression:** Classification predicts from a **limited set of outputs (e.g., 0 or 1)**, not an infinite range of numbers.
* **Data Representation:** Tumor size (X) can be plotted against a binary output (0 or 1). Even with multiple tumor types (e.g., Type 1, Type 2 cancer), the outputs remain discrete categories.
* **Output Classes/Categories:** These terms are interchangeable. Categories can be non-numeric (e.g., "cat" or "dog") or numeric (e.g., 0, 1, 2) but are always discrete, not continuous values like 0.5 or 1.7.

## Multiple Inputs in Classification

Classification problems can utilize **multiple input values** (features). For instance, in breast cancer detection, besides tumor size, **patient age** can be another input.

* With multiple inputs, a learning algorithm might find a **boundary line** to separate different categories (e.g., benign from malignant tumors) on a plot.
* Real-world applications often use **many more inputs** (e.g., tumor clump thickness, cell uniformity) to enhance prediction accuracy.

## Summary of Supervised Learning

Supervised learning maps input `X` to output `Y`, learning from "right answers." Its two main types are:

* **Regression:** Predicts a **number** from an infinite range (e.g., house prices).
* **Classification:** Predicts a **category** from a small, finite set of outputs (e.g., malignant/benign).

Next, we'll explore **unsupervised learning**, another major type of machine learning.

# Unsupervised Learning: Finding Structure in Data

**Unsupervised learning** is the second most widely used form of machine learning. Unlike supervised learning, it deals with **unlabeled data** (no 'y' outputs) and aims to **find inherent structure, patterns, or interesting insights** within the data itself. It's called "unsupervised" because the algorithm isn't given "right answers" to learn from; it figures out patterns on its own.

## Clustering: Grouping Unlabeled Data

A prominent type of unsupervised learning is **clustering**, which automatically groups unlabeled data into distinct clusters.

### Examples of Clustering:

* **Google News:** Groups hundreds of thousands of daily news articles into related stories (clusters) by identifying common words or themes. The algorithm autonomously determines these groupings without human pre-programming for specific topics.
* **Genetic/DNA Data Analysis:** Clusters individuals based on their genetic activity (e.g., from DNA microarrays) to identify different genetic "types" of people. This helps researchers uncover natural groupings in biological data.
* **Customer Segmentation:** Companies use clustering to automatically group customers into different market segments based on their data. This helps in efficiently serving diverse customer needs (e.g., DeepLearning.AI identified segments like "skill-seekers," "career developers," and "AI trend followers" within its community).

Clustering algorithms take unlabeled data and automatically group it into clusters. Besides clustering, there are other types of unsupervised learning. The next video will explore these further.

# Unsupervised Learning: Beyond Clustering

**Unsupervised learning** uses data with **inputs (x) only** (no output labels 'y') to find hidden **structure or patterns**. We previously discussed **clustering**, which groups similar data points.

## Other Unsupervised Learning Types:

This specialization also covers:

1.  **Anomaly Detection:** Identifies unusual events, crucial for **fraud detection** in finance and other applications.
2.  **Dimensionality Reduction:** Compresses large datasets into smaller ones with minimal information loss. (More details on these later in the specialization).

## Quiz: Supervised vs. Unsupervised Learning Examples

Here's a quick check on understanding:

* **Spam filtering:** **Supervised learning** (if labeled spam/non-spam data is available).
* **Grouping news stories:** **Unsupervised learning** (clustering, like Google News).
* **Market segmentation:** **Unsupervised learning** (discovering segments automatically from customer data).
* **Diagnosing diabetes:** **Supervised learning** (like breast cancer classification, with labeled diabetes/not diabetes data).

While clustering was the primary focus, we'll cover anomaly detection and dimensionality reduction in depth later.

# Supervised Learning: Linear Regression Fundamentals

This video introduces **Linear Regression**, a widely used supervised learning algorithm that **fits a straight line to data** for prediction. Concepts learned here are broadly applicable to other ML models.

## Predicting House Prices (Regression Example)

Using a dataset of house sizes and prices, we'll demonstrate linear regression:

* **Goal:** Predict a house's price (output, **y**) based on its size (input, **x**).
* **Method:** The model draws a straight line through existing data points. For a new house size, you follow this line to estimate the price.
* **Supervised Learning:** This is "supervised" because the model learns from a **training set** containing **"right answers"** (known house sizes with their corresponding prices).
* **Regression:** This is a **regression problem** because the output (price) is a **continuous numerical value**.
    * **Contrast with Classification:** Classification predicts discrete **categories** (e.g., cat/dog, specific diseases) from a finite set of outputs.

## Data Representation & Notation

Data can be visualized as a plot or a table. Standard ML notation for datasets:

* **Training Set:** The dataset used to train the model.
* **Input Variable (x):** Also called a **feature**. E.g., house size.
* **Output Variable (y):** Also called the **target variable**. E.g., house price.
* **m:** Total number of training examples (rows in the dataset).
* **$(x, y)$:** Denotes a single training example (input-output pair).
* **$x^{(i)}, y^{(i)}$:** Refers to the $i^{th}$ training example (the $i^{th}$ row in the data table). Note: $(i)$ is an index, not an exponent.

The next video will detail how this training set is used to train a learning algorithm.

# Supervised Learning Process: Linear Regression

Supervised learning algorithms take a **training set** (inputs 'x' and their correct 'y' outputs) and produce a **function (f)**, also called a **model**. This model, 'f', takes a new input 'x' and outputs a **prediction, ŷ, y-hat**. ŷ is predicted value, while y is the actual true value.

## Linear Regression Model

For now, we'll use a straight line function: $f_{w,b}(x) = wx + b$. Also, written as $f(x) = wx + b$.

* **w** and **b** are numerical parameters that define the line's slope and intercept.
* This function (or model) makes predictions (ŷ) based on input x.
* **Linear regression with one variable** (or **univariate linear regression**) uses a single input feature. Later, we'll cover models with multiple features.

## The Role of the Model

The learning algorithm **fits this linear function to the training data**, aiming to create the "best-fit" straight line. This line then provides predictions for new inputs.

## Important Note

**Regression models** predict **continuous numbers** (e.g., house prices). This contrasts with **classification models**, which predict discrete categories (e.g., cat/dog).

Next, we'll learn about the crucial concept of a **cost function**, essential for training virtually all ML models.

To implement linear regression, the first key step is defining a **cost function**. This function tells us how well our model performs, allowing us to improve it.

## Model Parameters and Function

Recall our linear function: $f_{w,b}(x) = wx + b$.
* **w** and **b** are the **parameters** (or coefficients/weights) of the model. We adjust these during training.
* Different values of **w** and **b** result in different lines on the graph (different functions $f(x)$).
    * **w** controls the **slope**.
    * **b** controls the **y-intercept**.
* Our goal is to choose **w** and **b** so that the line $f(x)$ **"fits the data well,"** meaning it passes close to the training examples.

## Measuring Model Fit: The Cost Function

For each training example $(x^{(i)}, y^{(i)})$, our model predicts $ŷ^{(i)} = f_{w,b}(x^{(i)})$. We want these predictions ($ŷ^{(i)}$) to be close to the actual target values ($y^{(i)}$).

To measure "how well" the line fits, we use a **cost function**, denoted as $J(w, b)$. For linear regression, we typically use the **squared error cost function**:

$J(w, b) = \frac{1}{2m} \sum_{i=1}^{m} (ŷ^{(i)} - y^{(i)})^2$

$J(w, b) = \frac{1}{2m} \sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2$

Let's break down this formula:
1.  **Error for each example:** $(f_{w,b}(x^{(i)}) - y^{(i)})$ is the difference between the model's prediction and the true target.
2.  **Squared Error:** We square this difference, $(f_{w,b}(x^{(i)}) - y^{(i)})^2$, to ensure errors don't cancel out and to penalize larger errors more heavily.
3.  **Summation:** $\sum_{i=1}^{m}$ sums these squared errors across all $m$ training examples.
4.  **Average:** Dividing by $m$ (and conventionally by $2m$) calculates the **average squared error**, preventing the cost from simply growing with the number of training examples. The division by 2 is for mathematical convenience in later calculations.

The **cost function $J(w, b)$** quantifies how "badly" our line fits the training data. A **smaller $J(w, b)$ value** means a **better-fitting line**.

The next video will build intuition about what different values of $J(w, b)$ signify.

# Cost Function: Intuition and Minimization

This video builds intuition for the **cost function**, $J(w, b)$, which measures how well our linear regression model $f_{w,b}(x) = wx + b$ fits the training data. Our goal is to **minimize $J(w, b)$** to find the optimal parameters $w$ and $b$.

## Simplified Model: $f_w(x) = wx$ (Setting $b=0$)

To visualize, we simplify the model to $f_w(x) = wx$, making $J$ a function of only one parameter, $w$.

* **Model $f_w(x)$:** A straight line passing through the origin (since $b=0$). $w$ is its slope.
* **Cost Function $J(w)$:**
    $J(w) = \frac{1}{2m} \sum_{i=1}^{m} (w \cdot x^{(i)} - y^{(i)})^2$
    This measures the average squared difference between the model's prediction and the true target values for a given $w$.

## Visualizing Model Fit and Cost

Let's use a simple training set: $(1,1), (2,2), (3,3)$.

1.  **If $w=1$:**
    * **Model $f_1(x) = 1x$:** This line perfectly fits the data points.
    * **Cost $J(1)$:** For each point, $f_1(x^{(i)}) - y^{(i)}$ is 0. So, $J(1) = 0$. This is the minimum possible cost, indicating a perfect fit.

2.  **If $w=0.5$:**
    * **Model $f_{0.5}(x) = 0.5x$:** This line has a shallower slope and doesn't perfectly align with the data.
    * **Cost $J(0.5)$:** There are errors (vertical distances) between the line and the data points. For example, at $x=1$, $f(1)=0.5$ while $y=1$, so the error is $0.5-1=-0.5$. Squaring and summing these errors gives a higher cost, $J(0.5) \approx 0.58$.

3.  **If $w=0$:**
    * **Model $f_0(x) = 0x$:** This is a horizontal line on the x-axis.
    * **Cost $J(0)$:** The errors are even larger, resulting in a higher cost, $J(0) \approx 2.33$.

By plotting $J(w)$ for various $w$ values, we trace out a **bowl-shaped curve**. The **lowest point on this curve corresponds to the $w$ value that minimizes the cost function**, giving the best fit to the data. In our simplified example, $w=1$ clearly minimizes $J(w)$ to 0.

## Conclusion for Linear Regression

The goal of linear regression is to **find the parameters ($w$ and $b$, or just $w$ in the simplified case) that minimize the cost function $J**. A smaller $J value signifies a better-fitting line.

The next video will visualize the cost function for the full linear regression model with both parameters, $w$ and $b$, using 3D plots.

# Visualizing the Cost Function $J(w, b)$

This video provides further visualizations of the **cost function $J(w,b)$** for linear regression, where $w$ and $b$ are the model parameters. The goal is to **minimize $J(w,b)$** to find the best-fitting line.

## 3D Surface Plot of $J(w, b)$

* Unlike the simplified $J(w)$ (U-shaped curve), $J(w,b)$ is a **3D, bowl-shaped surface**.
* The **w** and **b** axes form the base, and the **height** represents the value of $J(w,b)$ for specific $w$ and $b$ choices.
* Every point on this surface corresponds to a unique pair of $(w,b)$ values and their associated cost.
* For example, a model $f(x) = 0.06x + 50$ would have a specific $(w,b)$ point on this surface, representing its cost. This particular model might consistently underestimate housing prices, leading to a high cost.

## Contour Plots of $J(w,b)$

A **contour plot** offers a 2D representation of the 3D cost function surface.

* Imagine taking **horizontal slices** of the 3D bowl. Each slice, representing points with the **same cost value**, forms an **oval (ellipse)** on the 2D contour plot.
* The axes of the contour plot are **w** (horizontal) and **b** (vertical).
* **Concentric ovals** show different cost levels; the **smallest, innermost oval** represents the **minimum cost** at the bottom of the bowl.
* Points on the same oval have the same cost $J(w,b)$, even if their $w$ and $b$ values differ. These points correspond to different lines (functions $f(x)$) that might fit the data equally (and sometimes poorly).

The goal is to find the **(w, b) pair at the very center of the innermost oval** in the contour plot, as this represents the minimum cost $J(w,b)$, and thus the best-fitting line.

The next video will use these visualizations to show how different choices of $w$ and $b$ affect the straight line fit on the data.

# Gradient Descent Algorithm

This video introduces **Gradient Descent**, a widely used algorithm to **systematically find parameter values (w, b) that minimize the cost function J(w,b)**. It's applicable not only to linear regression but also to complex models like neural networks.

## How Gradient Descent Works

1.  **Objective:** Minimize the cost function $J(w, b)$ (or $J(w_1, \dots, w_n, b)$ for more parameters).
2.  **Initialization:** Start with initial guesses for $w$ and $b$ (e.g., both set to 0).
3.  **Iterative Adjustment:** Gradient descent **repeatedly adjusts parameters** (w and b) in small steps to **reduce the cost $J$**, hoping to converge near a minimum. (**Note**: there can be more than 1 values w, b for which there is global minima)

## Visualizing Gradient Descent (Hilly Landscape Analogy)

Imagine the cost function $J(w,b)$ as a hilly landscape, where height represents cost and valleys are minima.

* **Starting Point:** You begin at some point on this "hill" (corresponding to initial $w, b$ values).
* **Steepest Descent:** At each step, you **look around 360 degrees** and take a small step in the **direction that goes downhill fastest** (the "steepest descent"). This is the most efficient way to reduce cost locally.
* **Iteration:** You repeat this process, taking successive steps, until you reach the bottom of a valley, which is a **local minimum**.

## Local Minima

* For some complex cost functions (unlike the always bowl-shaped linear regression cost), there can be **multiple local minima**.
* **Starting point matters:** Where you start on the "hill" can determine which local minimum you converge to. If you start on a different part of the hill, you might end up in a different valley.

The next video will delve into the mathematical formulas required to implement gradient descent.

# Implementing Gradient Descent

This video details the implementation of the **Gradient Descent algorithm**, which iteratively updates model parameters (w and b) to minimize the cost function $J(w, b)$.

## Gradient Descent Algorithm Steps

For each parameter, the update rule is:

**$w = w - \alpha \frac{\partial}{\partial w} J(w, b)$**  
**$b = b - \alpha \frac{\partial}{\partial b} J(w, b)$**

Where:

* **`=` (Assignment Operator):** In this context, it means updating the variable on the left with the value computed on the right (e.g., `new_w = old_w - ...`).
* **$\alpha$ (Alpha):** The **learning rate**, a small positive number (e.g., 0.01). It controls the **size of the step** taken downhill.
    * **Large $\alpha$:** Aggressive, large steps.
    * **Small $\alpha$:** Small, "baby" steps.
* **$\frac{\partial}{\partial w} J(w, b)$ and $\frac{\partial}{\partial b} J(w, b)$ (Derivative Terms):** These terms tell us the **direction and steepness** of the "hill" at the current $(w,b)$ point. They indicate the direction of steepest descent. (No prior calculus knowledge is needed for this course).

## Simultaneous Update of Parameters

A crucial detail for correct gradient descent implementation is to **simultaneously update all parameters (w and b)**.

* **Correct (Simultaneous) Update:**
    1.  Calculate the new values for `w` and `b` based on their *current* (old) values and derivatives.
        * `temp_w = w - alpha * (d/dw J(w,b))`
        * `temp_b = b - alpha * (d/db J(w,b))`
    2.  Then, update `w = temp_w` and `b = temp_b`.
    This ensures both updates use the same, consistent starting point (the `w` and `b` values *before* any update in that step).

* **Incorrect (Non-Simultaneous) Update:**
    * If you update `w` first (e.g., `w = w - alpha * ...`) and then use this *new* `w` when calculating the update for `b`, it's incorrect. While it might sometimes "work," it's a different algorithm with different properties.

Gradient descent is repeated until convergence, meaning the parameters `w` and `b` no longer change significantly with each step, indicating a local minimum has been reached.

The next video will delve into the details of the derivative terms, providing the necessary intuition to implement gradient descent.

# Gradient Descent: Intuition Behind Derivatives and Learning Rate

This video provides intuition for the **gradient descent algorithm**:  

$w = w - \alpha \frac{\partial}{\partial w} J(w, b)$ (for the full model).  
$b = b - \alpha \frac{\partial}{\partial b} J(w, b)$ (for the full model).  

## Understanding the Derivative Term

The derivative (or partial derivative) term in the update rule represents the **slope of the cost function $J$ at the current parameter value $w$**.

Let's assume partial model only (assume b = 0)  
$w = w - \alpha \frac{\partial}{\partial w} J(w)$ (simplified to one parameter, $w$).  

* **Positive Slope:** If you are on the right side of the minimum, the tangent line to $J(w)$ has a positive slope.
    * Example: If derivative is +2.
    * Update: $w = w - \alpha \times (+2)$. Since $\alpha$ is positive, $w$ will **decrease**.
    * Effect: Moving $w$ to the **left**, closer to the minimum of $J(w)$.

* **Negative Slope:** If you are on the left side of the minimum, the tangent line to $J(w)$ has a negative slope.
    * Example: If derivative is -2.
    * Update: $w = w - \alpha \times (-2) = w + \alpha \times 2$. $w$ will **increase**.
    * Effect: Moving $w$ to the **right**, closer to the minimum of $J(w)$.

In both cases, the derivative term (scaled by $\alpha$) guides $w$ in the direction that **reduces the cost $J(w)$**, moving towards the minimum.

# Gradient Descent: The Importance of Learning Rate ($\alpha$)

The **learning rate ($\alpha$)** critically affects **gradient descent's efficiency and convergence**. The update rule is $W = W - \alpha \frac{\partial}{\partial W} J(W)$.

## Impact of $\alpha$ on Convergence:

* **$\alpha$ too small:** Leads to **slow convergence**. Steps are tiny, requiring many iterations to reach the minimum.
* **$\alpha$ too large:** Can cause **overshooting, oscillations, or divergence**, potentially failing to reach the minimum. The cost might even increase.

## Gradient Descent at a Local Minimum:

* If $W$ is at a **local minimum**, the **derivative $\frac{\partial}{\partial W} J(W)$ is zero**.
* The update becomes $W = W - \alpha \times 0 = W$, meaning the parameter **remains unchanged**, correctly staying at the minimum.

## Automatic Step Adjustment:

* As gradient descent approaches a local minimum, the **slope (derivative) naturally decreases**, becoming flatter.
* This automatically leads to **smaller update steps**, even with a fixed $\alpha$, allowing the algorithm to gradually settle into the minimum.

Gradient descent is a versatile optimization algorithm for any cost function $J$. Next, we'll combine it with the **mean squared error cost function** to build the **linear regression algorithm**.

# Linear Regression with Gradient Descent

This video combines the linear regression model, the squared error cost function, and the gradient descent algorithm to enable training.

## Derivatives for Gradient Descent

$J(w, b) = \frac{1}{2m} \sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})^2$

To implement gradient descent for linear regression, we need the partial derivatives of the cost function $J(w,b)$ with respect to $w$ and $b$:

* **Derivative w.r.t. $w$:**
    $\frac{\partial}{\partial w} J(w, b) = \frac{1}{m} \sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)}$
* **Derivative w.r.t. $b$:**
    $\frac{\partial}{\partial b} J(w, b) = \frac{1}{m} \sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})$

**(Optional Calculus Derivation):** These formulas are derived using calculus. The $1/2$ in the cost function ($1/2m$) was deliberately chosen so that the '2' from the power rule of differentiation cancels out, simplifying these derivative expressions.

## The Gradient Descent Algorithm for Linear Regression

The algorithm iteratively updates $w$ and $b$ simultaneously until convergence:

$w = w - \alpha \left( \frac{1}{m} \sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \right)$  
$b = b - \alpha \left( \frac{1}{m} \sum_{i=1}^{m} (f_{w,b}(x^{(i)}) - y^{(i)}) \right)$

where $f_{w,b}(x) = wx + b$ is the linear regression model.

## Convexity and Global Minimum

A key property of the squared error cost function used with linear regression is that it is **convex**.

* **Convex Function:** Informally, a "bowl-shaped" function. It has **only one global minimum** and no other local minima.
* **Impact on Gradient Descent:** For convex cost functions, as long as the learning rate $\alpha$ is appropriately chosen, gradient descent is **guaranteed to converge to the global minimum**, regardless of the starting point of $w$ and $b$.

## Batch Gradient Descent:

* Specific implementation we learned till now is called **batch gradient descent**.
* **"Batch"** refers to the fact that **every step of the algorithm uses *all* training examples** (the entire "batch" of data) to compute the derivatives for the parameter updates.
* Other versions of gradient descent exist that use subsets of data.
